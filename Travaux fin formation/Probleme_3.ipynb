{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.083208,
     "end_time": "2021-01-25T09:28:00.386282",
     "exception": false,
     "start_time": "2021-01-25T09:27:58.303074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re, nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Doc2Vec\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fousseyni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fousseyni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Fousseyni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008826,
     "end_time": "2021-01-25T09:28:00.404699",
     "exception": false,
     "start_time": "2021-01-25T09:28:00.395873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Je n'ai pris que la colonne \"review\" de l'ensemble de donn√©es car j'essaie de cr√©er un mod√®le de clustering bas√© sur les avis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì• Charger les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.158363,
     "end_time": "2021-01-25T09:28:01.571998",
     "exception": false,
     "start_time": "2021-01-25T09:28:00.413635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_test=load_files('texte/test/')\n",
    "data_train=load_files('texte/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conca= np.concatenate([np.array(data_train.data),np.array(data_test.data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data_conca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "papermill": {
     "duration": 15.493504,
     "end_time": "2021-01-25T09:28:17.114137",
     "exception": false,
     "start_time": "2021-01-25T09:28:01.620633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fousseyni\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Suppression des balises html des documents\n",
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    return text\n",
    "\n",
    "df[0] = df[0].apply(cleanText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full of (then) unknown actors TSF is a great b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amount of disappointment I am getting these da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The future, we are told, are what we make of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dan Katzir has produced a wonderful film that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you want Scream or anything like the big-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>After watching Tipping the Velvet by Sarah wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>The three main characters are all hopeless, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>I haven't reviewed on IMDb before but this doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Forget what I said about Emeril. Rachael Ray i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>What could've been a great film about the late...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      Full of (then) unknown actors TSF is a great b...\n",
       "1      Amount of disappointment I am getting these da...\n",
       "2      The future, we are told, are what we make of i...\n",
       "3      Dan Katzir has produced a wonderful film that ...\n",
       "4      If you want Scream or anything like the big-st...\n",
       "...                                                  ...\n",
       "99995  After watching Tipping the Velvet by Sarah wat...\n",
       "99996  The three main characters are all hopeless, an...\n",
       "99997  I haven't reviewed on IMDb before but this doc...\n",
       "99998  Forget what I said about Emeril. Rachael Ray i...\n",
       "99999  What could've been a great film about the late...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion de texte en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.202922,
     "end_time": "2021-01-25T09:28:17.327526",
     "exception": false,
     "start_time": "2021-01-25T09:28:17.124604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[0] = df[0].apply(lambda x: x.lower()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppression des mots vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "papermill": {
     "duration": 22.700946,
     "end_time": "2021-01-25T09:28:40.041294",
     "exception": false,
     "start_time": "2021-01-25T09:28:17.340348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "df[0] = df[0].apply(lambda x: \" \".join(x for x in x.split() if x not in english_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppression des mots non anglais et des mots d'une longueur inf√©rieure √† 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "papermill": {
     "duration": 4.741259,
     "end_time": "2021-01-25T09:28:44.794319",
     "exception": false,
     "start_time": "2021-01-25T09:28:40.053060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "df[0] = df[0].apply(lambda x: \" \".join(i for i in nltk.wordpunct_tokenize(x) if i in words and len(i) > 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer les mots en sa forme racine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "papermill": {
     "duration": 19.12928,
     "end_time": "2021-01-25T09:29:03.934061",
     "exception": false,
     "start_time": "2021-01-25T09:28:44.804781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer() \n",
    "df[0] = df[0].apply(lambda x: ' '.join(lm.lemmatize(i) for i in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Fousseyni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplacer tout autre chose que les mots et les espaces par un espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "papermill": {
     "duration": 0.557185,
     "end_time": "2021-01-25T09:29:04.501896",
     "exception": false,
     "start_time": "2021-01-25T09:29:03.944711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fousseyni\\AppData\\Local\\Temp\\ipykernel_15540\\2361613010.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[0] = df[0].str.replace('[^\\w\\s]',' ')\n"
     ]
    }
   ],
   "source": [
    "df[0] = df[0].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©paration des donn√©es pour la formation doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "papermill": {
     "duration": 0.221398,
     "end_time": "2021-01-25T09:29:04.734084",
     "exception": false,
     "start_time": "2021-01-25T09:29:04.512686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts processed:  100000\n"
     ]
    }
   ],
   "source": [
    "LabeledSentence = gensim.models.doc2vec.TaggedDocument\n",
    "all_content_train = []\n",
    "j=0\n",
    "for em in df[0].values:\n",
    "    all_content_train.append(LabeledSentence(em,[j]))\n",
    "    j+=1\n",
    "print('Nombre de textes trait√©s: ', j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√®le de formation doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "papermill": {
     "duration": 213.36921,
     "end_time": "2021-01-25T09:32:38.114501",
     "exception": false,
     "start_time": "2021-01-25T09:29:04.745291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec(all_content_train, vector_size = 100, window = 10, min_count = 500, workers=7, dm = 1,alpha=0.025, min_alpha=0.001)\n",
    "d2v_model.train(all_content_train, total_examples=d2v_model.corpus_count, epochs=10, start_alpha=0.002, end_alpha=-0.016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D√©termination du nombre de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "papermill": {
     "duration": 46.62432,
     "end_time": "2021-01-25T09:33:24.750637",
     "exception": false,
     "start_time": "2021-01-25T09:32:38.126317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fousseyni\\AppData\\Local\\Temp\\ipykernel_15540\\2076997197.py:5: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  kmeans.fit(d2v_model.docvecs.vectors_docs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'vectors_docs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15540\\2076997197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mwcss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwcss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'vectors_docs'"
     ]
    }
   ],
   "source": [
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n",
    "    kmeans.fit(d2v_model.dv.vectors_docs)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.title('La m√©thode ELBOW')\n",
    "plt.xlabel('le nombre de clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√®le de formation doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 2.677202,
     "end_time": "2021-01-25T09:33:27.439611",
     "exception": false,
     "start_time": "2021-01-25T09:33:24.762409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6820\\2767736406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans_model = KMeans(n_clusters=4, init='k-means++', max_iter=100, n_init=10,random_state=0) \n",
    "X = kmeans_model.fit(d2v_model.docvecs.vectors_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trac√© des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.072587,
     "end_time": "2021-01-25T09:33:31.530330",
     "exception": false,
     "start_time": "2021-01-25T09:33:27.457743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = kmeans_model.labels_.tolist()\n",
    "l = kmeans_model.fit_predict(d2v_model.docvecs.vectors_docs)\n",
    "pca = PCA(n_components=2).fit(d2v_model.docvecs.vectors_docs)\n",
    "datapoint = pca.transform(d2v_model.docvecs.vectors_docs)\n",
    "\n",
    "plt.figure\n",
    "label1 = ['#FFFF00', '#008000', '#0000FF', '#800080']\n",
    "color = [label1[i] for i in labels]\n",
    "plt.scatter(datapoint[:, 0], datapoint[:, 1], c=color)\n",
    "centroids = kmeans_model.cluster_centers_\n",
    "centroidpoint = pca.transform(centroids)\n",
    "plt.scatter(centroidpoint[:, 0], centroidpoint[:, 1], marker='^', s=150, c='#000000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde du mod√®le et chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "papermill": {
     "duration": 0.020788,
     "end_time": "2021-01-25T09:33:31.564485",
     "exception": false,
     "start_time": "2021-01-25T09:33:31.543697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(kmeans_model, open('model_v1', 'wb'))\n",
    "loaded_model = pickle.load(open('model_v1', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.02162,
     "end_time": "2021-01-25T09:33:31.599114",
     "exception": false,
     "start_time": "2021-01-25T09:33:31.577494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['label'] = loaded_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tracer la distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.170041,
     "end_time": "2021-01-25T09:33:31.782277",
     "exception": false,
     "start_time": "2021-01-25T09:33:31.612236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['label'].value_counts().plot(kind='bar', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 10.457116,
     "end_time": "2021-01-25T09:33:42.253925",
     "exception": false,
     "start_time": "2021-01-25T09:33:31.796809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tracer un cluster\n",
    "label = df[df['label'] == 0]\n",
    "print(label.shape)\n",
    "text = ''\n",
    "for i in label.index:\n",
    "    text += ' ' + label['review'][i]\n",
    "\n",
    "# Cr√©ez et g√©n√©rez une image de nuage de mots¬†:\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "\n",
    "# Affichez l'image g√©n√©r√©e¬†:\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "duration": 348.83434,
   "end_time": "2021-01-25T09:33:43.292436",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-25T09:27:54.458096",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
